{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef94d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from enum import Enum, auto\n",
    "\n",
    "from preproc import CleanSentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cbb1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set lang to work with in the notebook\n",
    "lang = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa53d08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 1911276\n"
     ]
    }
   ],
   "source": [
    "# load vocabulary\n",
    "vocab = json.load(open(join('data', 'lang_corpus', lang,'vocab.json'), 'r'))\n",
    "print('vocab size:', len(vocab.keys()))\n",
    "reverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2326c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      toxic_sentence  \\\n",
      "0  then all of a sudden i see her , shes now got ...   \n",
      "1  My page should be protected first so that wort...   \n",
      "2                        You made a mistake you ass.   \n",
      "3  you know more than these idiots , stay the cou...   \n",
      "4     piss me off , fuckin jerk , get on my nerves .   \n",
      "\n",
      "                                    neutral_sentence  \n",
      "0    All of a sudden i see her, she is all grown up.  \n",
      "1  My page should be protected first so that unpl...  \n",
      "2                                You made a mistake.  \n",
      "3  you know more than these people , stay the cou...  \n",
      "4                                   get on my nerves  \n",
      "(400, 2)\n"
     ]
    }
   ],
   "source": [
    "# load toxic dataset\n",
    "df = pd.read_csv(join('data', 'pan', f'{lang}.tsv'), sep='\\t', encoding='utf8')\n",
    "print(df.head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3342d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic words: 3007\n"
     ]
    }
   ],
   "source": [
    "# and toxic word list\n",
    "toxic_words = set(json.load(open(join('data', 'en_toxic_vocab.json'), 'r')))\n",
    "print('toxic words:', len(toxic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "422988f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Query(gram_counts:dict, gram_ids:tuple) -> tuple:\n",
    "    look_back = gram_ids[:-1]\n",
    "    if type(look_back) is not tuple:\n",
    "        look_back = tuple(look_back)\n",
    "        \n",
    "    # assemble queries to consider the entire vocabulary\n",
    "    queries = []\n",
    "    for id in vocab.values():\n",
    "        queries.append(look_back + (id,))\n",
    "    # print(queries[:5])\n",
    "    \n",
    "    # get each query's frequency\n",
    "    candidates = {}\n",
    "    for query in queries:\n",
    "        if query in gram_counts:\n",
    "            candidates[query] = gram_counts[query]\n",
    "    \n",
    "    if len(candidates) == 0: return (-1,) #empty space, which will result in deleting the gram\n",
    "\n",
    "    # sort candidates by frequency\n",
    "    candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)\n",
    "    # print('top 10 candidates:', candidates[:5])\n",
    "\n",
    "    # return top candidate or random of top ones, if there is a tie\n",
    "    top_candidates = [c[0] for c in candidates if c[1] == candidates[0][1]]\n",
    "    return top_candidates[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60a6c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vocab_ids = [vid for vid in vocab.values() if reverse_vocab[vid] not in toxic_words] #filter out toxic word ids\n",
    "\n",
    "def QueryGeneral(gram_counts: dict, gram_ids: list) -> tuple:\n",
    "    if -2 not in gram_ids: \n",
    "        # print('no wildcard token')\n",
    "        return tuple([-1] * len(gram_ids))\n",
    "    \n",
    "    # assumes only one wildcard\n",
    "    wildcard_index = gram_ids.index(-2)\n",
    "    candidates = {}\n",
    "    for vid in clean_vocab_ids: #only consider queries of non-toxic words to guarantee replacement with non-toxic or empty\n",
    "        temp = list(gram_ids) #copy the list\n",
    "        temp[wildcard_index] = vid\n",
    "        query = tuple(temp)\n",
    "        if query in gram_counts:\n",
    "            candidates[query] = gram_counts[query] #get freq of this ngram\n",
    "\n",
    "    if not candidates: \n",
    "        # print('no candidates')\n",
    "        return tuple([-1] * len(gram_ids))\n",
    "\n",
    "    # Sort and return the most frequent match (or one of them)\n",
    "    candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_candidates = [c[0] for c in candidates if c[1] == candidates[0][1]]\n",
    "    return top_candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64fdf24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize(s:str, n:int) -> list[int]:\n",
    "    s = CleanSentence(s) #clean the same as in the training script\n",
    "    tokens = [vocab[w] for w in s.split() if w in vocab] # convert each word to its id, if it exists in the vocabulary, otherwise it is ignored\n",
    "    if len(tokens) < n:\n",
    "        return []\n",
    "    tokens = [-1] * (n - 1) + tokens + [-1] * (n - 1) #pad with the -1 token on either end, bcs i want the ngram model to handle sentence boundaries\n",
    "    return tokens # convert string to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb05fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Untokenize(gram_ids:tuple):\n",
    "    # convert tuple to list to enable modification\n",
    "    gram_ids = list(gram_ids)\n",
    "\n",
    "    # convert ids to words\n",
    "    for i, id in enumerate(gram_ids):\n",
    "        gram_ids[i] = reverse_vocab[id]\n",
    "    return ' '.join(gram_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e17a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryStrategy(Enum):\n",
    "    LOOKBACK = auto()\n",
    "    LOOKFORWARD = auto()\n",
    "    CENTER = auto()\n",
    "\n",
    "def RunModel(cp_df, n, model, strategy):\n",
    "    print(f'Processing {n}-gram model {strategy.name} strategy...')\n",
    "    \n",
    "    model_col = f'{n}-gram-{strategy.name}'\n",
    "    cp_df[model_col] = '' # create a new column for the n-gram model predictions\n",
    "\n",
    "    # add n-grams prediction for each toxic sentence\n",
    "    for i, row in cp_df.iterrows():\n",
    "        toxic_sent = row['toxic_sentence']\n",
    "        toxic_ids = Tokenize(toxic_sent, n)\n",
    "        if len(toxic_ids) == 0: continue\n",
    "\n",
    "        # replace each toxic word with the n-gram model prediction\n",
    "        for j, id in enumerate(toxic_ids):\n",
    "            if j < n-1 or j > len(toxic_ids)-n: continue #skip over padding tokens\n",
    "\n",
    "            if reverse_vocab[id] in toxic_words:\n",
    "                if strategy == QueryStrategy.LOOKBACK:\n",
    "                    context = toxic_ids[j-n+1 : j+1]\n",
    "                    wildcard_idx = n - 1\n",
    "                elif strategy == QueryStrategy.LOOKFORWARD:\n",
    "                    context = toxic_ids[j : j+n]\n",
    "                    wildcard_idx = 0\n",
    "                elif strategy == QueryStrategy.CENTER:\n",
    "                    back = n // 2\n",
    "                    context = toxic_ids[j-back+1 : j+back+1]\n",
    "                    wildcard_idx = back\n",
    "\n",
    "                # inject the single wildcard\n",
    "                # print(j, wildcard_idx, toxic_ids, toxic_ids[j], context, Untokenize(context))\n",
    "                context[wildcard_idx] = -2\n",
    "                # print(context)\n",
    "                replacement = QueryGeneral(model, context)\n",
    "                # print(replacement)\n",
    "                # print(replacement[wildcard_idx])\n",
    "                toxic_ids[j] = replacement[wildcard_idx] #replace with last id of replacement tuple\n",
    "                # print(toxic_ids, Untokenize(toxic_ids))\n",
    "            \n",
    "        # if i > 4: return\n",
    "\n",
    "        # remove all -1 tokens, as they are meaningless empty space\n",
    "        toxic_ids = [t for t in toxic_ids if t != -1]\n",
    "\n",
    "        # convert back to string\n",
    "        pred_sent = Untokenize(toxic_ids)\n",
    "        # add in original sentence ending punctuation\n",
    "        ending = re.search(r'[^\\w]+$', toxic_sent)\n",
    "        if ending:\n",
    "            pred_sent += ending.group(0)\n",
    "        pred_sent = pred_sent[0].upper() + pred_sent[1:] #capitalize start of sentence\n",
    "        # save down\n",
    "        cp_df.at[i, model_col] = pred_sent\n",
    "\n",
    "        if i % 25 == 0:\n",
    "            print(f'{i}...', end='\\r')\n",
    "\n",
    "        # if i > 4: break #testing\n",
    "\n",
    "    print('Saving dataframes...')\n",
    "    # save in the formats required by the eval scripts\n",
    "    sub = cp_df.copy() #submission\n",
    "    ref = cp_df.copy() #reference\n",
    "\n",
    "    sub = sub[['toxic_sentence', model_col]]\n",
    "    ref = ref[['toxic_sentence', 'neutral_sentence']]\n",
    "\n",
    "    sub['lang'] = lang #specify for eval script\n",
    "    ref['lang'] = lang #specify for eval script\n",
    "\n",
    "    sub = sub[sub[model_col].notna()] #remove NaN rows\n",
    "\n",
    "    sub.columns = ['toxic_sentence', 'neutral_sentence', 'lang'] #specify for eval script\n",
    "    ref.columns = ['toxic_sentence', 'neutral_sentence', 'lang'] #specify for eval script\n",
    "\n",
    "    os.makedirs(join('preds', lang), exist_ok=True)\n",
    "    sub.to_csv(join('preds', lang, f'{n}-gram_{strategy.name}_sub.tsv'), index=False, sep='\\t', encoding='utf8')\n",
    "    ref.iloc[:len(sub)].to_csv(join('preds', lang, f'{n}-gram_{strategy.name}_ref.tsv'), index=False, sep='\\t', encoding='utf8')\n",
    "    \n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "529082b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2-gram model...\n",
      "Processing 2-gram model LOOKBACK strategy...\n",
      "Saving dataframes...\n",
      "Done\n",
      "Loading 3-gram model...\n",
      "Processing 3-gram model LOOKBACK strategy...\n",
      "Saving dataframes...\n",
      "Done\n",
      "Loading 4-gram model...\n",
      "Processing 4-gram model LOOKBACK strategy...\n",
      "Saving dataframes...\n",
      "Done\n",
      "Processing 4-gram model LOOKFORWARD strategy...\n",
      "Saving dataframes...\n",
      "Done\n",
      "Processing 4-gram model CENTER strategy...\n",
      "Saving dataframes...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for model_path in glob(join('models', 'ngrams', '*.pkl')):\n",
    "    n = int(os.path.basename(model_path).split('-')[0])\n",
    "    # if n != 2: continue\n",
    "    cp_df = df.copy() #local copy so that original df doesnt keep growing\n",
    "    \n",
    "    model = None\n",
    "    print(f'Loading {n}-gram model...')\n",
    "    with open(model_path, 'rb') as model_file:\n",
    "        model = pickle.load(model_file)\n",
    "    \n",
    "    if n == 4:\n",
    "        for strategy in [QueryStrategy.LOOKBACK,QueryStrategy.LOOKFORWARD,QueryStrategy.CENTER]:\n",
    "            RunModel(cp_df, n, model, strategy)\n",
    "    else:\n",
    "        RunModel(cp_df, n, model, QueryStrategy.LOOKBACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace each toxic word with the n-gram model prediction\n",
    "for strategy in [QueryStrategy.LOOKBACK,QueryStrategy.LOOKFORWARD,QueryStrategy.CENTER]:\n",
    "    n = 4\n",
    "    toxic_ids = [-1] * (n - 1) + list(range(1,4)) + [-1] * (n - 1)\n",
    "    print(toxic_ids)\n",
    "    for j, id in enumerate(toxic_ids):\n",
    "        if j < n-1: continue\n",
    "        if j > len(toxic_ids)-n: continue\n",
    "        if strategy == QueryStrategy.LOOKBACK:\n",
    "            print(j, j-n+1)\n",
    "            context = toxic_ids[j-n+1 : j+1]    # list of length n\n",
    "            wildcard_idx = n - 1             # wildcard at end\n",
    "        elif strategy == QueryStrategy.LOOKFORWARD:\n",
    "            print(j, j+n)\n",
    "            context = toxic_ids[j : j+n]    # list of length n\n",
    "            wildcard_idx = 0                 # wildcard at start\n",
    "        elif strategy == QueryStrategy.CENTER:\n",
    "            back = n // 2\n",
    "            print(j-back, j+back+1)\n",
    "            context = toxic_ids[j-back+1 : j+back+1]  # list of length n\n",
    "            wildcard_idx = back             # center slot\n",
    "\n",
    "        # inject the single wildcard\n",
    "        context[wildcard_idx] = -2\n",
    "        print(strategy, wildcard_idx, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick test\n",
    "# sent = (4, 320, 0)\n",
    "# print(model[sent])\n",
    "# pred = Query(model, sent)\n",
    "# print(pred, Untokenize(pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
